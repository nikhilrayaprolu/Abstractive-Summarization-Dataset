{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# arguments related to the dataset\n",
    "parser.add_argument(\"--data_dir\",type=str, default='/home/mjc/datasets/CNN_DailyMail/cnn/stories_merged_100/',\n",
    "                    help='directory where data files are located')\n",
    "parser.add_argument(\"--word2idx\",type=str, default='word2idx.npy', help='file name for word2idx file')\n",
    "parser.add_argument(\"--idx2word\",type=str, default='idx2word.npy', help='file name for idx2word file')\n",
    "parser.add_argument(\"--max_enc\",type=int, default=400, help='max length of encoder sequence')\n",
    "parser.add_argument(\"--max_dec\",type=int, default=100, help='max length of decoder sequence')\n",
    "parser.add_argument(\"--min_dec\",type=int, default=35, help='min length of decoder sequence')\n",
    "parser.add_argument(\"--vocab_size\",type=int, default=50000, help='vocabulary size')\n",
    "parser.add_argument(\"--max_oovs\",type=int, default=20, help='max number of OOVs to accept in a sample')\n",
    "\n",
    "\n",
    "# arguments related to model training and inference\n",
    "parser.add_argument(\"--train\",type=bool, default=True, help='train/test model. Set by default to True(=train)')\n",
    "parser.add_argument(\"--epochs\",type=int, default=20, help='Number of epochs. Set by default to 20')\n",
    "parser.add_argument(\"--load_model\",type=str, default='', help='input model name to start from a pretrained model')\n",
    "parser.add_argument(\"--hidden\",type=int, default=256, help='size of hidden dimension')\n",
    "parser.add_argument(\"--embed\",type=int, default=128, help='size of embedded word dimension')\n",
    "parser.add_argument(\"--lr\",type=float, default=0.15, help='learning rate')\n",
    "parser.add_argument(\"--cov_lambda\",type=float, default=1.0, help='lambda for coverage loss')\n",
    "parser.add_argument(\"--beam\",type=int, default=4, help='beam size')\n",
    "parser.add_argument(\"--cuda\",type=bool, default=True, help='whether to use GPU')\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "from packages.vocab import Vocab\n",
    "from packages.batch import Batch\n",
    "from model import Model\n",
    "from packages.functions import to_cuda, num_to_var\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import os\n",
    "import random\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as pad\n",
    "\n",
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    data_dir='cnn_stories_batch'\n",
    "    word2idx='word2idx.npy'\n",
    "    idx2word='idx2word.npy'\n",
    "    max_enc=200\n",
    "    max_dec=50\n",
    "    min_dec=35\n",
    "    vocab_size=50000\n",
    "    max_oovs = 20\n",
    "    \n",
    "    train = True\n",
    "    epochs = 20\n",
    "    load_model = ''\n",
    "    hidden_size = 256\n",
    "    embed_size = 128\n",
    "    lr = 0.15\n",
    "    cov_lambda = 1.0\n",
    "    beam = 4\n",
    "    cuda = True\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab = Vocab(args.vocab_size)\n",
    "vocab.w2i = np.load(args.word2idx).item()\n",
    "vocab.i2w = np.load(args.idx2word).item()\n",
    "vocab.count = len(vocab.w2i)\n",
    "\n",
    "# obtain dataset in batches\n",
    "file_list = os.listdir(args.data_dir)\n",
    "batch = Batch(file_list, args.max_enc, args.max_dec, args.max_oovs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3-1:  0.0005803108215332031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhinav.appidi/nikhil/GetToThePoint/model.py:112: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  attn = F.softmax(attn2.view(b,in_seq)) # [b x in_seq]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-2,3:  0.3252391815185547\n",
      "3-4,5,6,7:  0.0012030601501464844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhinav.appidi/nikhil/GetToThePoint/model.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p_vocab = F.softmax(self.V2(self.V1(torch.cat([state.squeeze(),context],1)))) # [b x vocab]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-8.2:  0.008010387420654297\n",
      "3-8.3:  0.39261388778686523\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Performing basic indexing on a tensor and encountered an error indexing dim 0 with an object of type torch.LongTensor. The only supported types are integers, slices, numpy scalars, or if indexing with a torch.cuda.LongTensor or torch.cuda.ByteTensor only a single Tensor may be passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-b07d66588ed3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mminibatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mstories\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msummaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mout_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# get packed versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nikhil/GetToThePoint/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target, batch, vocab, train)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mp_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mword_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mp_copy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword_indices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx_repeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mIndexSelect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# else fall through and raise an error in Index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new/lib/python3.5/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, index)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_shared_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Performing basic indexing on a tensor and encountered an error indexing dim 0 with an object of type torch.LongTensor. The only supported types are integers, slices, numpy scalars, or if indexing with a torch.cuda.LongTensor or torch.cuda.ByteTensor only a single Tensor may be passed."
     ]
    }
   ],
   "source": [
    "\n",
    "# load model\n",
    "if args.load_model != '':\n",
    "    model = torch.load(args.load_model)\n",
    "else:\n",
    "    model = Model(args)\n",
    "model = to_cuda(model)\n",
    "\n",
    "# get loss and optimizers\n",
    "opt = optim.Adam(params=model.parameters(),lr=args.lr)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# computation for each epoch\n",
    "epoch = 0\n",
    "while (epoch<args.epochs):\n",
    "    epoch+=1\n",
    "    random.shuffle(file_list)\n",
    "    for file in file_list:\n",
    "        opt.zero_grad()\n",
    "        with open(os.path.join(args.data_dir,file),encoding='utf-8') as f:\n",
    "            minibatch = f.read()\n",
    "        stories,summaries = batch.process_minibatch(minibatch,vocab)\n",
    "        out_list, cov_loss = model(stories, summaries, batch, vocab, True)\n",
    "        \n",
    "        # get packed versions\n",
    "        target = num_to_var(summaries[:,1:])\n",
    "        target = pack(target, batch.output_lens.to_list(),batch_first=True)[0]\n",
    "        pad_out = pack(out_list, batch.output_lens.to_list(),batch_first=True)[0]\n",
    "        pad_out = torch.log(pad_out)\n",
    "        loss = criterion(pad_out,target)+cov_loss\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        print(\"got thru batch!\")\n",
    "# if __name__ == \"__main__\":\n",
    "#     main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros([10,40],dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for selective masking while preserving sizes\n",
    "from collections import Counter \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "numbers = stories.reshape(-1).tolist()\n",
    "set_numbers = list(set(numbers))\n",
    "c = Counter(numbers)\n",
    "dup_list = [k for k in set_numbers if c[k] > 1]\n",
    "print(\"Number of iters: %d\" % len(dup_list))\n",
    "elapsed = time.time()\n",
    "print(\"Time elapsed: \", elapsed-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dup in dup_list[0:1]:\n",
    "    mask = np.array(stories==dup,dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = np.random.randn(mask.shape[0],mask.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = mask*attn.sum(1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "mask2 = Variable(torch.Tensor(mask).cuda())\n",
    "attn2 = Variable(torch.Tensor(attn).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2=torch.mul(mask2, attn2.sum(1).unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn2[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "hidden_dim = 256\n",
    "embed_dim = 128\n",
    "batch_size = 16\n",
    "num_samples = 92579\n",
    "max_encoder_steps = 400\n",
    "max_decoder_steps = 100\n",
    "beam_size = 4\n",
    "min_decoder_steps = 35 # min size of generated sequence\n",
    "vocab_size = 50000\n",
    "lr = 0.15\n",
    "adagrad_init_acc = 0.1 # deprecated for pytorch\n",
    "rand_unif_init_mag = 0.02 # magnitude for lstm cells during random init\n",
    "trunc_norm_init_std = 1e-4 # std of truncated norm initialization\n",
    "max_grad_norm = 2.0 # so they do apply gradient clipping\n",
    "max_oovs = 20 # maximum number of oovs allowed?\n",
    "coverage_loss = 1.0 # lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get vocabulary\n",
    "vocab = Vocab(50000)\n",
    "vocab.w2i = np.load('word2idx.npy').item()\n",
    "vocab.i2w = np.load('idx2word.npy').item()\n",
    "vocab.count = len(vocab.w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset in batches\n",
    "file_dir = 'cnn_stories_batch'\n",
    "args.data_dir ='cnn_stories_batch'\n",
    "file_list = os.listdir(file_dir)\n",
    "batch = Batch(file_list,200,50,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  454     5   815    52    50    51    29 35143  5782     5     4  1239\n",
      "    14   195    88  2148     5    18     9   846 50001    43  2666     4\n",
      "   751  4221  1444     8  2201    14  4758     6    11   578     5    49\n",
      "  2628     4 35143  5782  1488    16   184     5   116    49 35160  1767\n",
      "     7  2095  1145  5814    11   481     5   217  1710  1310     4   636\n",
      "   626     6    49  1094    24    50    14   846   184   220    55    54\n",
      "  2352     7 24252  7288    16   184     5    54  1464    33     9   328\n",
      "    17   991   146    10   112    49 15620    54  2653   169    24    54\n",
      "  1639   160     6    50    44    69  4945    32    45   111  2012     8\n",
      "    85 35143  5782    44    91   246   367     5    20    14    98   186\n",
      "     5    15    14     4    88   425    15   654   136   219  2012     6\n",
      "    16    98   229   187     5    20    70    34    65    26   535     9\n",
      "  2201    14  4758    11  3847     6    26    22     4 31867   344   409\n",
      "     7   345     9  2201    14  4758     5    82    20    22   147     9\n",
      "  1149  1845   425     6    50    44    69   812    32    45   111  5248\n",
      "    55    85 43554    44     4   425    26   183     7   161   117    26\n",
      "  1591    18   184  7268   482  3739    11     4] [50002 35143  5782     5   502     8   195  1239  4789  2952  5782     5\n",
      "    18     9   846 50001    11  1164     6    40  4221    16   184    14\n",
      "   250     5    49   421     4 35143  5782  1488    16   184     6  5782\n",
      "  1553    50    55    54  2303     7   910    10 16152    54   594    10\n",
      "  2653 50003]\n",
      "[   52    50    51    29  1009    18  7557    19   568     7  1041  4831\n",
      "   196   931   129  1322   696     6   112    41  1321    96  2848     4\n",
      "   233  4239    33   225     7     4   742   985     6   568    30    47\n",
      "    56     7   606   166   816     7  4755  1322   696  8954   107    29\n",
      "    41    96  3064     7 23323    15     4  3343    11 26602   666  1213\n",
      "    59    91 11035    80  1322   696     6    35    25  2717    30 15698\n",
      "    71   336     4    86     6    10   746     5 46296   148   383   268\n",
      "    10  5655    59   836   816    33  4206   268     5  1922   347   606\n",
      "    59   816     6   102   120    10  1212   735    30   346 25752     7\n",
      "     4   258     8   843     6     4  9559     8  4501    10  2467    33\n",
      "     4  1086 50001  5335    24     4   102    14   229  2752 50002     5\n",
      " 11465  4350     5   684     7  2206     4  1793    16   331    14   505\n",
      "  7967     5    10  2816    15    41   606  1192  2449     6    82  1735\n",
      "    18     4  2208    15    84  2656   977    15   614 22745    32  5971\n",
      "  9411     4   931     6    64    32  3508   719    25     7   274     4\n",
      "   102    18  2396  1764     4   173  1090    37 21340    71 31821   903\n",
      "     4  4115     5   761     4   865   793   794] [50003  4322    44   893    36  4431  4755  1322  1209    82   326     5\n",
      "    35    20    36     7  4392   115   493     6   735    30   364    19\n",
      "     4 11465  5021     8  1889  5533     5    41   122     6   353   478\n",
      "    59  2146    24  1036  3138   174     4   254   243   230  5917     4\n",
      "  5965 50004]\n"
     ]
    }
   ],
   "source": [
    "from packages.batch import Batch\n",
    "for file in file_list[1:3]:\n",
    "        with open(os.path.join(args.data_dir,file),encoding = 'utf-8') as f:\n",
    "            \n",
    "            minibatch = f.read()\n",
    "\n",
    "        stories,summaries = batch.process_minibatch(minibatch,vocab)\n",
    "        print(stories[0], summaries[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stories' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e078a20ae3c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stories' is not defined"
     ]
    }
   ],
   "source": [
    "print(stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch.init_minibatch()\n",
    "with open(os.path.join(file_dir,file_list[70])) as f:\n",
    "    minibatch = f.read()\n",
    "    minibatch = minibatch.split('\\n\\n')\n",
    "    minibatch = [line for line in minibatch if not line.startswith(\":==:\")]\n",
    "stories, summaries = batch.process_minibatch(minibatch,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stories[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx=22\n",
    "' '.join(vocab.idx_list_to_word_list(stories[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch.idx2oov_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "' '.join(vocab.idx_list_to_word_list(stories[idx],batch.idx2oov_list[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unked = batch.unk_minibatch(stories[idx],vocab)\n",
    "' '.join(vocab.idx_list_to_word_list(unked,batch.idx2oov_list[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "' '.join(vocab.idx_list_to_word_list(summaries[idx],batch.idx2oov_list[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "help(nn.LSTMCell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch.oov2idx_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.ones([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

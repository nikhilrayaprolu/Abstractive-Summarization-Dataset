{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# arguments related to the dataset\n",
    "parser.add_argument(\"--data_dir\",type=str, default='/home/mjc/datasets/CNN_DailyMail/cnn/stories_merged_100/',\n",
    "                    help='directory where data files are located')\n",
    "parser.add_argument(\"--word2idx\",type=str, default='word2idx.npy', help='file name for word2idx file')\n",
    "parser.add_argument(\"--idx2word\",type=str, default='idx2word.npy', help='file name for idx2word file')\n",
    "parser.add_argument(\"--max_enc\",type=int, default=400, help='max length of encoder sequence')\n",
    "parser.add_argument(\"--max_dec\",type=int, default=100, help='max length of decoder sequence')\n",
    "parser.add_argument(\"--min_dec\",type=int, default=35, help='min length of decoder sequence')\n",
    "parser.add_argument(\"--vocab_size\",type=int, default=50000, help='vocabulary size')\n",
    "parser.add_argument(\"--max_oovs\",type=int, default=20, help='max number of OOVs to accept in a sample')\n",
    "\n",
    "\n",
    "# arguments related to model training and inference\n",
    "parser.add_argument(\"--train\",type=bool, default=True, help='train/test model. Set by default to True(=train)')\n",
    "parser.add_argument(\"--epochs\",type=int, default=20, help='Number of epochs. Set by default to 20')\n",
    "parser.add_argument(\"--load_model\",type=str, default='', help='input model name to start from a pretrained model')\n",
    "parser.add_argument(\"--hidden\",type=int, default=256, help='size of hidden dimension')\n",
    "parser.add_argument(\"--embed\",type=int, default=128, help='size of embedded word dimension')\n",
    "parser.add_argument(\"--lr\",type=float, default=0.15, help='learning rate')\n",
    "parser.add_argument(\"--cov_lambda\",type=float, default=1.0, help='lambda for coverage loss')\n",
    "parser.add_argument(\"--beam\",type=int, default=4, help='beam size')\n",
    "parser.add_argument(\"--cuda\",type=bool, default=True, help='whether to use GPU')\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "from packages.vocab import Vocab\n",
    "from packages.batch import Batch\n",
    "from model import Model\n",
    "from packages.functions import to_cuda, num_to_var\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import os\n",
    "import random\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as pad\n",
    "\n",
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    data_dir='/home/mjc/datasets/CNN_DailyMail/cnn/stories_merged_100/'\n",
    "    word2idx='word2idx.npy'\n",
    "    idx2word='idx2word.npy'\n",
    "    max_enc=400\n",
    "    max_dec=100\n",
    "    min_dec=35\n",
    "    vocab_size=50000\n",
    "    max_oovs = 20\n",
    "    \n",
    "    train = True\n",
    "    epochs = 20\n",
    "    load_model = ''\n",
    "    hidden_size = 256\n",
    "    embed_size = 128\n",
    "    lr = 0.15\n",
    "    cov_lambda = 1.0\n",
    "    beam = 4\n",
    "    cuda = True\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor sizes at /home/mjc/github/pytorch/torch/lib/TH/generic/THTensorMath.c:489",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7da0dcd1ffc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mminibatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mstories\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msummaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mout_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# get packed versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mjc/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mjc/projects/GetToThePoint/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target, batch, vocab, train)\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                                 \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [b x in_seq x vocab+oov]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                                 \u001b[0mone_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                                 \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                                 \u001b[0mp_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvie2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor sizes at /home/mjc/github/pytorch/torch/lib/TH/generic/THTensorMath.c:489"
     ]
    }
   ],
   "source": [
    "# def main(args):\n",
    "# obtain vocabulary\n",
    "vocab = Vocab(args.vocab_size)\n",
    "vocab.w2i = np.load(args.word2idx).item()\n",
    "vocab.i2w = np.load(args.idx2word).item()\n",
    "vocab.count = len(vocab.w2i)\n",
    "\n",
    "# obtain dataset in batches\n",
    "file_list = os.listdir(args.data_dir)\n",
    "batch = Batch(file_list, args.max_enc, args.max_dec, args.max_oovs)\n",
    "\n",
    "# load model\n",
    "if args.load_model != '':\n",
    "    model = torch.load(args.load_model)\n",
    "else:\n",
    "    model = Model(args)\n",
    "model = to_cuda(model)\n",
    "\n",
    "# get loss and optimizers\n",
    "opt = optim.Adam(params=model.parameters(),lr=args.lr)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# computation for each epoch\n",
    "epoch = 0\n",
    "while (epoch<args.epochs):\n",
    "    epoch+=1\n",
    "    random.shuffle(file_list)\n",
    "    for file in file_list:\n",
    "        opt.zero_grad()\n",
    "        with open(os.path.join(args.data_dir,file)) as f:\n",
    "            minibatch = f.read()\n",
    "        stories,summaries = batch.process_minibatch(minibatch,vocab)\n",
    "        out_list, cov_loss = model(stories, summaries, batch, vocab, True)\n",
    "        \n",
    "        # get packed versions\n",
    "        target = num_to_var(summaries[:,1:])\n",
    "        target = pack(target, batch.output_lens.to_list(),batch_first=True)[0]\n",
    "        pad_out = pack(out_list, batch.output_lens.to_list(),batch_first=True)[0]\n",
    "        pad_out = torch.log(pad_out)\n",
    "        loss = criterion(pad_out,target)+cov_loss\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        print(\"got thru batch!\")\n",
    "# if __name__ == \"__main__\":\n",
    "#     main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = torch.randn(4,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_x = torch.LongTensor([0,0,1,2])\n",
    "idx_y = torch.LongTensor([3,5,8,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "indexing a tensor with an object of type torch.LongTensor. The only supported types are integers, slices, numpy scalars and torch.LongTensor or torch.ByteTensor as the only argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2d6097dbd7c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: indexing a tensor with an object of type torch.LongTensor. The only supported types are integers, slices, numpy scalars and torch.LongTensor or torch.ByteTensor as the only argument."
     ]
    }
   ],
   "source": [
    "A[idx_x,idx_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.arange(20,dtype=float).reshape([2,5,-1])\n",
    "b = np.ones(100,dtype=float).reshape([2,5,-1])*40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "A = Variable(torch.Tensor(a))\n",
    "B = Variable(torch.Tensor(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A.expand_as(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "hidden_dim = 256\n",
    "embed_dim = 128\n",
    "batch_size = 16\n",
    "num_samples = 92579\n",
    "max_encoder_steps = 400\n",
    "max_decoder_steps = 100\n",
    "beam_size = 4\n",
    "min_decoder_steps = 35 # min size of generated sequence\n",
    "vocab_size = 50000\n",
    "lr = 0.15\n",
    "adagrad_init_acc = 0.1 # deprecated for pytorch\n",
    "rand_unif_init_mag = 0.02 # magnitude for lstm cells during random init\n",
    "trunc_norm_init_std = 1e-4 # std of truncated norm initialization\n",
    "max_grad_norm = 2.0 # so they do apply gradient clipping\n",
    "max_oovs = 20 # maximum number of oovs allowed?\n",
    "coverage_loss = 1.0 # lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get vocabulary\n",
    "vocab = Vocab(50000)\n",
    "vocab.w2i = np.load('word2idx.npy').item()\n",
    "vocab.i2w = np.load('idx2word.npy').item()\n",
    "vocab.count = len(vocab.w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get dataset in batches\n",
    "file_dir = '/home/mjc/datasets/CNN_DailyMail/cnn/stories_merged_100/'\n",
    "file_list = os.listdir(file_dir)\n",
    "batch = Batch(file_list,400,100,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch.init_minibatch()\n",
    "with open(os.path.join(file_dir,file_list[70])) as f:\n",
    "    minibatch = f.read()\n",
    "    minibatch = minibatch.split('\\n\\n')\n",
    "    minibatch = [line for line in minibatch if not line.startswith(\":==:\")]\n",
    "stories, summaries = batch.process_minibatch(minibatch,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stories[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx=22\n",
    "' '.join(vocab.idx_list_to_word_list(stories[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch.idx2oov_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "' '.join(vocab.idx_list_to_word_list(stories[idx],batch.idx2oov_list[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unked = batch.unk_minibatch(stories[idx],vocab)\n",
    "' '.join(vocab.idx_list_to_word_list(unked,batch.idx2oov_list[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "' '.join(vocab.idx_list_to_word_list(summaries[idx],batch.idx2oov_list[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "help(nn.LSTMCell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch.oov2idx_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.ones([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
